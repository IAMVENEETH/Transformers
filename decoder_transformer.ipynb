{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "1jbLBkMjoYKw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MultiheadAttention"
      ],
      "metadata": {
        "id": "Q-LQGmznztpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ofKVYHPzlaAt"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self,d_model,num_heads):\n",
        "    super(MultiheadAttention,self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_model // num_heads\n",
        "    self.qkv_layer = nn.Linear(d_model,3*d_model)\n",
        "    self.linear_layer = nn.Linear(d_model,d_model)\n",
        "\n",
        "  def forward(self,x,mask):\n",
        "    qkv = self.qkv_layer(x)# 30 X 200 X 1536\n",
        "    print(f\"qkv_layer{qkv.shape}\")\n",
        "    qkv = qkv.reshape(batch_size,self.num_heads,max_sequence_length,3*self.head_dim)# 30 X 8 X 200 X 192\n",
        "    print(f\"qkv_layer{qkv.shape}\")\n",
        "    q,k,v = qkv.chunk(3,dim=-1)\n",
        "    d_k = q.shape[-1]\n",
        "    scaled = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(d_k)# 30 X 8 X 200 X 192\n",
        "    print(f\"scaled_layer{scaled.shape}\")\n",
        "    scaled += mask\n",
        "    self_attention = torch.softmax(scaled,dim=-1)# 30 X 8 X 200 X 192\n",
        "    print(f\"attention_matrix {self_attention.shape}\")\n",
        "    out = torch.matmul(self_attention,v)# 30 X 8 X 200 X 192\n",
        "    out = out.reshape(batch_size,max_sequence_length,self.num_heads*self.head_dim)# 30 X 200 X 512\n",
        "    print(f\"out_shape {out.shape}\")\n",
        "    out = self.linear_layer(out)# 30 X 200 X 512\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MultiheadCrossAttention"
      ],
      "metadata": {
        "id": "xs-YQvMSzrGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadCrossAttention(nn.Module):\n",
        "  def __init__(self,d_model,num_heads):\n",
        "    super(MultiheadCrossAttention,self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_model // num_heads\n",
        "    self.kv_layer = nn.Linear(d_model,2*d_model)\n",
        "    self.q_layer = nn.Linear(d_model,d_model)\n",
        "    self.linear_layer = nn.Linear(d_model,d_model)\n",
        "  def forward(self,x,y,mask=None):\n",
        "    kv = self.kv_layer(x)\n",
        "    print(f\"kv_layer {kv.shape}\")\n",
        "    q = self.q_layer(x)\n",
        "    print(f\"q_layer {q.shape}\")\n",
        "\n",
        "    kv = kv.reshape(batch_size,self.num_heads,max_sequence_length,2*self.head_dim)\n",
        "    print(f\"kv_layer {kv.shape}\")\n",
        "    q = q.reshape(batch_size,self.num_heads,max_sequence_length,self.head_dim)\n",
        "    print(f\"q_layer {q.shape}\")\n",
        "\n",
        "    k,v = kv.chunk(2,dim=-1)\n",
        "    d_k = q.shape[-1]\n",
        "    scaled = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(d_k)# 30 X 8 X 200 X 192\n",
        "    print(f\"scaled_layer {scaled.shape}\")\n",
        "    self_attention = torch.softmax(scaled,dim=-1)# 30 X 8 X 200 X 192\n",
        "    print(f\"attention_matrix {self_attention.shape}\")\n",
        "    out = torch.matmul(self_attention,v)# 30 X 8 X 200 X 192\n",
        "    out = out.reshape(batch_size,max_sequence_length,self.num_heads*self.head_dim)# 30 X 200 X 512\n",
        "    print(f\"out_shape {out.shape}\")\n",
        "    out = self.linear_layer(out)# 30 X 200 X 512\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "pIxl851otuPj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LayerNormalization"
      ],
      "metadata": {
        "id": "BRX_sdITzn-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self,parameter_size,eps=1e-5):\n",
        "    super().__init__()\n",
        "    self.parameter_size = parameter_size#[512]\n",
        "    self.eps = eps\n",
        "    self.gamma = nn.Parameter(torch.ones(parameter_size))#[512]\n",
        "    self.beta = nn.Parameter(torch.zeros(parameter_size))#[512]\n",
        "\n",
        "  def forward(self,x):\n",
        "    dims = [(-i+1) for i in range(len(self.parameter_size))]#[-1]\n",
        "    print(f\"dims {dims}\")\n",
        "    mean = x.mean(dim=dims, keepdim=True)# 30 x 200 x 1\n",
        "    var=((x-mean)**2).mean(dim=dims, keepdim=True)# 30 x 200 x 1\n",
        "    std_ = (var+self.eps).sqrt()# 30 x 200 x 1\n",
        "    y = (x - mean) / std_# 30 x 200 x 512\n",
        "    out = self.gamma * y + self.beta# 30 x 200 x 512\n",
        "    print(f\"out_shape {out.shape}\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "vbmiTRZZlmfe"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PositionWisefeedForward"
      ],
      "metadata": {
        "id": "88cBfSHUzkVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "  def __init__(self,d_model,ffn_hidden,drop_prob):\n",
        "    super().__init__()\n",
        "    self.linear_layer_1 = nn.Linear(d_model,ffn_hidden)#512 x 2048\n",
        "    self.linear_layer_2 = nn.Linear(ffn_hidden,d_model)#2048 x 512\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "  def forward(self,x):\n",
        "    x = self.linear_layer_1(x)# 30 x 200 x 2048\n",
        "    print(f\"linear_layer {x.shape}\")\n",
        "    x = self.relu(x)# 30 x 200 x 2048\n",
        "    x = self.dropout(x)# 30 x 200 x 2048\n",
        "    x = self.linear_layer_2(x)# 30 x 200 x 512\n",
        "    print(f\"linear_layer {x.shape}\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "NNHr-ElklqQ6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decode Layer"
      ],
      "metadata": {
        "id": "h0w2dutQzg-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decode_layer(nn.Module):\n",
        "  def __init__(self,d_model,num_heads,drop_prob,ffn_hidden):\n",
        "    super(Decode_layer,self).__init__()\n",
        "\n",
        "    self.attention = MultiheadAttention(d_model,num_heads)\n",
        "\n",
        "    self.norm1 = LayerNormalization([d_model])\n",
        "    self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    self.cross_attention = MultiheadCrossAttention(d_model,num_heads)\n",
        "\n",
        "    self.norm2 = LayerNormalization([d_model])\n",
        "    self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    self.ffn = PositionwiseFeedForward(d_model,ffn_hidden,drop_prob)\n",
        "    self.norm3 = LayerNormalization([d_model])\n",
        "    self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def forward(self,x,y,decoder_mask):\n",
        "    print(\"Starting epoch...\")\n",
        "    residual_x = x # 30 x 200 x 512\n",
        "    x = self.attention(x,decoder_mask) # 30 X 200 X 512\n",
        "    print(\"Attention done.\")\n",
        "    x = self.dropout1(x)# 30 X 200 X 512\n",
        "    x = self.norm1(x+residual_x)# 30 X 200 X 512\n",
        "    print(\"normalization completed\")\n",
        "    x = self.cross_attention(x,y,mask=None) # 30 X 200 X 512\n",
        "    print(\"cross_Attention done.\")\n",
        "    x = self.dropout2(x)# 30 X 200 X 512\n",
        "    x = self.norm2(x+residual_x)# 30 X 200 X 512\n",
        "    print(\"normalization completed\")\n",
        "    residual_x = x# 30 X 200 X 512\n",
        "    x = self.ffn(x)# 30 X 200 X 512\n",
        "    print(\"feed forwarded\")\n",
        "    x = self.dropout3(x)# 30 X 200 X 512\n",
        "    x = self.norm3(x+residual_x)# 30 X 200 X 512\n",
        "    print(\"normalization completed\")\n",
        "    print(\"-------------------------------------------------\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "s1w3kmlamHGv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential_decoder(nn.Sequential):\n",
        "  def forward(self,*inputs):\n",
        "    x ,y, mask = inputs\n",
        "    for module in self._modules.values():\n",
        "      y = module(x,y,mask)\n",
        "    return y"
      ],
      "metadata": {
        "id": "xZs8aPOSrvSD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "EQrzQaibzdNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,d_model,num_heads,drop_prob,ffn_hidden,num_layers):\n",
        "    super().__init__()\n",
        "    self.decode_layer = Sequential_decoder(*[Decode_layer(d_model,num_heads,drop_prob,ffn_hidden) for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self,x,y,mask):\n",
        "    x = self.decode_layer(x,y,mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "KHp-dr0YruU8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "num_heads = 8\n",
        "d_model = 512\n",
        "ffn_hidden = 2048\n",
        "drop_prob = 0.1\n",
        "num_layers = 5"
      ],
      "metadata": {
        "id": "2cqX5Ycjvcqt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Input"
      ],
      "metadata": {
        "id": "UM2XkmJ4zaEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((batch_size,max_sequence_length,d_model))\n",
        "y = torch.randn((batch_size,max_sequence_length,d_model))"
      ],
      "metadata": {
        "id": "iZ1xn0KjvcfS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(d_model,num_heads,drop_prob,ffn_hidden,num_layers)"
      ],
      "metadata": {
        "id": "Gj7dscNDv3l4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.full((max_sequence_length,max_sequence_length),float('-inf'))\n",
        "mask = torch.triu(mask,diagonal=1)"
      ],
      "metadata": {
        "id": "PATvwyTawB5o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = decoder(x,y,mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO2wsR8qwkTp",
        "outputId": "6ea2132e-0551-4911-8ee0-c4f25fe10b35"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch...\n",
            "qkv_layertorch.Size([30, 200, 1536])\n",
            "qkv_layertorch.Size([30, 8, 200, 192])\n",
            "scaled_layertorch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "kv_layer torch.Size([30, 200, 1024])\n",
            "q_layer torch.Size([30, 200, 512])\n",
            "kv_layer torch.Size([30, 8, 200, 128])\n",
            "q_layer torch.Size([30, 8, 200, 64])\n",
            "scaled_layer torch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "cross_Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "linear_layer torch.Size([30, 200, 2048])\n",
            "linear_layer torch.Size([30, 200, 512])\n",
            "feed forwarded\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "-------------------------------------------------\n",
            "Starting epoch...\n",
            "qkv_layertorch.Size([30, 200, 1536])\n",
            "qkv_layertorch.Size([30, 8, 200, 192])\n",
            "scaled_layertorch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "kv_layer torch.Size([30, 200, 1024])\n",
            "q_layer torch.Size([30, 200, 512])\n",
            "kv_layer torch.Size([30, 8, 200, 128])\n",
            "q_layer torch.Size([30, 8, 200, 64])\n",
            "scaled_layer torch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "cross_Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "linear_layer torch.Size([30, 200, 2048])\n",
            "linear_layer torch.Size([30, 200, 512])\n",
            "feed forwarded\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "-------------------------------------------------\n",
            "Starting epoch...\n",
            "qkv_layertorch.Size([30, 200, 1536])\n",
            "qkv_layertorch.Size([30, 8, 200, 192])\n",
            "scaled_layertorch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "kv_layer torch.Size([30, 200, 1024])\n",
            "q_layer torch.Size([30, 200, 512])\n",
            "kv_layer torch.Size([30, 8, 200, 128])\n",
            "q_layer torch.Size([30, 8, 200, 64])\n",
            "scaled_layer torch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "cross_Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "linear_layer torch.Size([30, 200, 2048])\n",
            "linear_layer torch.Size([30, 200, 512])\n",
            "feed forwarded\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "-------------------------------------------------\n",
            "Starting epoch...\n",
            "qkv_layertorch.Size([30, 200, 1536])\n",
            "qkv_layertorch.Size([30, 8, 200, 192])\n",
            "scaled_layertorch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "kv_layer torch.Size([30, 200, 1024])\n",
            "q_layer torch.Size([30, 200, 512])\n",
            "kv_layer torch.Size([30, 8, 200, 128])\n",
            "q_layer torch.Size([30, 8, 200, 64])\n",
            "scaled_layer torch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "cross_Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "linear_layer torch.Size([30, 200, 2048])\n",
            "linear_layer torch.Size([30, 200, 512])\n",
            "feed forwarded\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "-------------------------------------------------\n",
            "Starting epoch...\n",
            "qkv_layertorch.Size([30, 200, 1536])\n",
            "qkv_layertorch.Size([30, 8, 200, 192])\n",
            "scaled_layertorch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "kv_layer torch.Size([30, 200, 1024])\n",
            "q_layer torch.Size([30, 200, 512])\n",
            "kv_layer torch.Size([30, 8, 200, 128])\n",
            "q_layer torch.Size([30, 8, 200, 64])\n",
            "scaled_layer torch.Size([30, 8, 200, 200])\n",
            "attention_matrix torch.Size([30, 8, 200, 200])\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "cross_Attention done.\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "linear_layer torch.Size([30, 200, 2048])\n",
            "linear_layer torch.Size([30, 200, 512])\n",
            "feed forwarded\n",
            "dims [1]\n",
            "out_shape torch.Size([30, 200, 512])\n",
            "normalization completed\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}