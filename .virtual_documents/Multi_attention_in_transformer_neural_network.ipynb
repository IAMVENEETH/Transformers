import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as f


sequence_length = 4
batch_size = 1
input_dim = 512
d_model = 512

x = torch.randn((batch_size,sequence_length,input_dim))


x.shape


qkv_layer = nn.Linear(input_dim,3*input_dim)



qkv = qkv_layer(x)


qkv.shape


num_heads = 8
head_dim = d_model//num_heads
qkv = qkv.reshape(batch_size,sequence_length,num_heads,3*head_dim)


qkv.shape


qkv = qkv.permute(0,2,1,3)


qkv.shape


q,k,v = qkv.chunk(3,dim=-1)


q.shape,k.shape,v.shape








import math
d_k = q.size()[-1]
_n = torch.matmul(q,k.transpose(-2,-1))
_d = math.sqrt(d_k)
_f = _n/_d

mask = torch.full(_f.shape,float('-inf'))
mask = torch.triu(mask,diagonal=1)


_f_ = _f + mask
_f_ = torch.softmax(_f_,dim=-1)
v_new = torch.matmul(_f_,v)


v_new.shape


v_new = v_new.reshape(batch_size,sequence_length,num_heads*head_dim)


v_new.shape


linear_l = nn.Linear(d_model,d_model)


v_new = linear_l(v_new)


v_new.shape



